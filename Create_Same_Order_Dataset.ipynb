{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使 majority 和其他能夠比較，把訓練資料用成一樣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from Dental_Tool.Data_processing import *\n",
    "from Dental_Tool.Dental_Model import *\n",
    "from Dental_Tool.Process_results import *\n",
    "from Dental_Tool.Dataloader import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"balance_dataset/Class_3_majority_70_Chang_168\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_2_HV_Info(dataframe):\n",
    "        \n",
    "        if \"multitask_key\" not in dataframe.columns: \n",
    "                for idx, row in dataframe.iterrows():\n",
    "                            multitask_key = row[\"ID\"] + \"_\" + row[\"side\"]   \n",
    "                            dataframe.loc[idx, \"multitask_key\"]  = multitask_key \n",
    "        \n",
    "        HV_Dict = {}\n",
    "        HV_info = pd.read_csv(\"HV_Table_Clean_20201120.csv\")\n",
    "        \n",
    "        for idx, row in HV_info.iterrows():\n",
    "                tooth_num = row[\"tooth_num\"][:-1]\n",
    "                if not tooth_num.isdigit():\n",
    "                        self.PBL_Table.drop(idx, inplace=True)\n",
    "                        continue\n",
    "                else:\n",
    "\n",
    "                        if  9 <= int(tooth_num) <= 24: # L--> M, R-->D\n",
    "                                if \"M\" in row[\"tooth_num\"]:\n",
    "                                        row[\"tooth_num\"] = tooth_num + \"_L\"\n",
    "                                if \"D\" in row[\"tooth_num\"]:\n",
    "                                        row[\"tooth_num\"] = tooth_num + \"_R\"\n",
    "\n",
    "                        elif 1 <= int(tooth_num) <= 8 or 24 < int(tooth_num) <= 32:\n",
    "                                if \"M\" in row[\"tooth_num\"]:\n",
    "                                        row[\"tooth_num\"] = tooth_num + \"_R\"\n",
    "                                if \"D\" in row[\"tooth_num\"]:\n",
    "                                        row[\"tooth_num\"] = tooth_num + \"_L\"\n",
    "\n",
    "                        else:\n",
    "                                print(row)\n",
    "                                raise ValueError\n",
    "\n",
    "                multitask_key = row[\"sub_dir_name\"] + \"_\" + row[\"image_name\"] + \"_\" + row[\"tooth_num\"]                     \n",
    "                HV_info.loc[idx,\"multitask_key\"] = multitask_key\n",
    "                HV_Dict[multitask_key] = row[\"Configuration\"]\n",
    "\n",
    "        HV_information = []\n",
    "        for idx, row in dataframe.iterrows():\n",
    "                HV_info = HV_Dict.get(row[\"multitask_key\"], \"empty\")\n",
    "                if HV_info == \"empty\": HV_information.append(-999)\n",
    "                else : HV_information.append(HV_info)\n",
    "                        \n",
    "        dataframe[\"bone_loss\"] = HV_information\n",
    "#         new_HV_data = pd.merge(dataframe, HV_info, on='multitask_key', how='left', suffixes=['_Original', '_HVData'])\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pattern(dataframe): \n",
    "        pattern_list = []\n",
    "        for item in dataframe[\"Path\"]:\n",
    "                item_split_slash = item.split(\"/\")\n",
    "\n",
    "                is_clahe = item_split_slash[-2].find(\"clahe\")\n",
    "                is_Flip  = item_split_slash[-2].find(\"Flip\")\n",
    "\n",
    "                dir_pattern =  \"\"\n",
    "                if   is_clahe == -1 and is_Flip == -1 : dir_pattern = \"Ori\"\n",
    "                elif is_clahe != -1 and is_Flip == -1 : dir_pattern = \"clahe\"\n",
    "                elif is_clahe == -1 and is_Flip != -1 : dir_pattern = \"flip\"\n",
    "                elif is_clahe != -1 and is_Flip != -1 : dir_pattern = \"clahe_flip\"\n",
    "\n",
    "                all_pattern = \"_\".join(item_split_slash[-1].split(\"_\")[1:])\n",
    "                all_pattern = dir_pattern + \"_\" + all_pattern \n",
    "                pattern_list.append(all_pattern)\n",
    "        dataframe[\"pattern\"] = pattern_list\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sheng_ID = [\"002555 042513 x\", \"000408 102419 x\", \"005627 120209 x\", \"004151 091409 x\",\n",
    "            \"003615 010816 x\", \"007274 021016 x\", \"007274 021016 x\", \"004359 030716 x\",\n",
    "            \"001742 082712 x\", \"002456 060517 x\", \"1899 120718 x\", \"004499 110515 x\",\n",
    "            \"13529 092513 x\",  \"000411 112119 x\", \"008908 090309 x\", \"003262 103015 x\",\n",
    "            \"10689 102418 x\", \"003670 020718 x\", \"010953 031618 x\", ]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meng 50 + Chang 168 + Sheng 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = [ \n",
    "                \"Dental_Data/PBL/10_interdental_20200902_Max_4\", \n",
    "                \"Dental_Data/PBL/10_interdental_20200902_Max_4_Flip\", \n",
    "                \"Dental_Data/PBL/10_interdental_clahe_20200902_Max_4\", \n",
    "                \"Dental_Data/PBL/10_interdental_clahe_20200902_Max_4_Flip\",\n",
    "            ]\n",
    "\n",
    "directory = [ i + \"/mapping.json\" for i in directory]\n",
    "argscale_num = len(directory) * 20 \n",
    "\n",
    "data = load_json(directory, interdental=True)\n",
    "dataset = json_2_dataframe_PBL_inderdental(data)\n",
    "\n",
    "Chang_Meng_Sheng = find_pattern(dataset)\n",
    "Chang_Meng_Sheng = map_2_HV_Info(Chang_Meng_Sheng)\n",
    "Chang_Meng_Sheng = Chang_Meng_Sheng[ (Chang_Meng_Sheng.State >= 0) & (Chang_Meng_Sheng.bone_loss >= 0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000408 102419 x',\n",
       " '000411 112119 x',\n",
       " '001742 082712 x',\n",
       " '002456 060517 x',\n",
       " '002555 042513 x',\n",
       " '003262 103015 x',\n",
       " '003615 010816 x',\n",
       " '003670 020718 x',\n",
       " '004151 091409 x',\n",
       " '004359 030716 x',\n",
       " '004499 110515 x',\n",
       " '005627 120209 x',\n",
       " '007274 021016 x',\n",
       " '008908 090309 x',\n",
       " '010953 031618 x',\n",
       " '10689 102418 x',\n",
       " '13529 092513 x',\n",
       " '1899 120718 x'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Chang_Meng_Sheng.ID) & set(Sheng_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chang 168 + 50 + 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = [ \n",
    "                \"Dental_Data/PBL/10_interdental_20201110_Max_4\", \n",
    "                \"Dental_Data/PBL/10_interdental_20201110_Max_4_Flip\", \n",
    "                \"Dental_Data/PBL/10_interdental_clahe_20201110_Max_4\", \n",
    "                \"Dental_Data/PBL/10_interdental_clahe_20201110_Max_4_Flip\",\n",
    "            ]\n",
    "\n",
    "directory = [ i + \"/mapping.json\" for i in directory]\n",
    "argscale_num = len(directory) * 20 \n",
    "\n",
    "data = load_json(directory, interdental=True)\n",
    "dataset = json_2_dataframe_PBL_inderdental(data)\n",
    "\n",
    "Chang = find_pattern(dataset)\n",
    "Chang = map_2_HV_Info(Chang)\n",
    "Chang = Chang[ (Chang.State >= 0) & (Chang.bone_loss >= 0) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>State</th>\n",
       "      <th>Class</th>\n",
       "      <th>ID</th>\n",
       "      <th>ori_src</th>\n",
       "      <th>source</th>\n",
       "      <th>tooth_num</th>\n",
       "      <th>tooth_type</th>\n",
       "      <th>side</th>\n",
       "      <th>multitask_key</th>\n",
       "      <th>angle</th>\n",
       "      <th>pattern</th>\n",
       "      <th>bone_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_20201110_Max_4/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000408 102419 x</td>\n",
       "      <td>NN_191024_151623_BE78A8</td>\n",
       "      <td>NN_191024_151623_BE78A8_6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>000408 102419 x_NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>-10</td>\n",
       "      <td>Ori_000408 102419 x_NN_191024_151623_BE78A8_6_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_20201110_Max_4_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000408 102419 x</td>\n",
       "      <td>NN_191024_151623_BE78A8</td>\n",
       "      <td>NN_191024_151623_BE78A8_6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>000408 102419 x_NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>-10</td>\n",
       "      <td>flip_000408 102419 x_NN_191024_151623_BE78A8_6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_clahe_20201110_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000408 102419 x</td>\n",
       "      <td>NN_191024_151623_BE78A8</td>\n",
       "      <td>NN_191024_151623_BE78A8_6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>000408 102419 x_NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>-10</td>\n",
       "      <td>clahe_000408 102419 x_NN_191024_151623_BE78A8_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_clahe_20201110_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000408 102419 x</td>\n",
       "      <td>NN_191024_151623_BE78A8</td>\n",
       "      <td>NN_191024_151623_BE78A8_6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>000408 102419 x_NN_191024_151623_BE78A8_6_L</td>\n",
       "      <td>-10</td>\n",
       "      <td>clahe_flip_000408 102419 x_NN_191024_151623_BE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_20201110_Max_4/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>000408 102419 x</td>\n",
       "      <td>NN_191024_151623_BE78A8</td>\n",
       "      <td>NN_191024_151623_BE78A8_6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>NN_191024_151623_BE78A8_6_R</td>\n",
       "      <td>000408 102419 x_NN_191024_151623_BE78A8_6_R</td>\n",
       "      <td>-10</td>\n",
       "      <td>Ori_000408 102419 x_NN_191024_151623_BE78A8_6_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625115</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_clahe_20201110_...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>S594966_2 091718 x</td>\n",
       "      <td>NN_180917_113933_C0A0B2</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26_L</td>\n",
       "      <td>S594966_2 091718 x_NN_180917_113933_C0A0B2_26_L</td>\n",
       "      <td>9</td>\n",
       "      <td>clahe_flip_S594966_2 091718 x_NN_180917_113933...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625116</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_20201110_Max_4/...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S594966_2 091718 x</td>\n",
       "      <td>NN_180917_113933_C0A0B2</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>9</td>\n",
       "      <td>Ori_S594966_2 091718 x_NN_180917_113933_C0A0B2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625117</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_20201110_Max_4_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S594966_2 091718 x</td>\n",
       "      <td>NN_180917_113933_C0A0B2</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>9</td>\n",
       "      <td>flip_S594966_2 091718 x_NN_180917_113933_C0A0B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625118</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_clahe_20201110_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S594966_2 091718 x</td>\n",
       "      <td>NN_180917_113933_C0A0B2</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>9</td>\n",
       "      <td>clahe_S594966_2 091718 x_NN_180917_113933_C0A0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625119</th>\n",
       "      <td>Dental_Data/PBL/10_interdental_clahe_20201110_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S594966_2 091718 x</td>\n",
       "      <td>NN_180917_113933_C0A0B2</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R</td>\n",
       "      <td>9</td>\n",
       "      <td>clahe_flip_S594966_2 091718 x_NN_180917_113933...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>591600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Path  State  Class  \\\n",
       "0       Dental_Data/PBL/10_interdental_20201110_Max_4/...      1      0   \n",
       "1       Dental_Data/PBL/10_interdental_20201110_Max_4_...      1      0   \n",
       "2       Dental_Data/PBL/10_interdental_clahe_20201110_...      1      0   \n",
       "3       Dental_Data/PBL/10_interdental_clahe_20201110_...      1      0   \n",
       "4       Dental_Data/PBL/10_interdental_20201110_Max_4/...      1      0   \n",
       "...                                                   ...    ...    ...   \n",
       "625115  Dental_Data/PBL/10_interdental_clahe_20201110_...      2      1   \n",
       "625116  Dental_Data/PBL/10_interdental_20201110_Max_4/...      1      0   \n",
       "625117  Dental_Data/PBL/10_interdental_20201110_Max_4_...      1      0   \n",
       "625118  Dental_Data/PBL/10_interdental_clahe_20201110_...      1      0   \n",
       "625119  Dental_Data/PBL/10_interdental_clahe_20201110_...      1      0   \n",
       "\n",
       "                        ID                  ori_src  \\\n",
       "0          000408 102419 x  NN_191024_151623_BE78A8   \n",
       "1          000408 102419 x  NN_191024_151623_BE78A8   \n",
       "2          000408 102419 x  NN_191024_151623_BE78A8   \n",
       "3          000408 102419 x  NN_191024_151623_BE78A8   \n",
       "4          000408 102419 x  NN_191024_151623_BE78A8   \n",
       "...                    ...                      ...   \n",
       "625115  S594966_2 091718 x  NN_180917_113933_C0A0B2   \n",
       "625116  S594966_2 091718 x  NN_180917_113933_C0A0B2   \n",
       "625117  S594966_2 091718 x  NN_180917_113933_C0A0B2   \n",
       "625118  S594966_2 091718 x  NN_180917_113933_C0A0B2   \n",
       "625119  S594966_2 091718 x  NN_180917_113933_C0A0B2   \n",
       "\n",
       "                            source  tooth_num  tooth_type  \\\n",
       "0        NN_191024_151623_BE78A8_6          6           2   \n",
       "1        NN_191024_151623_BE78A8_6          6           2   \n",
       "2        NN_191024_151623_BE78A8_6          6           2   \n",
       "3        NN_191024_151623_BE78A8_6          6           2   \n",
       "4        NN_191024_151623_BE78A8_6          6           2   \n",
       "...                            ...        ...         ...   \n",
       "625115  NN_180917_113933_C0A0B2_26         26           3   \n",
       "625116  NN_180917_113933_C0A0B2_26         26           3   \n",
       "625117  NN_180917_113933_C0A0B2_26         26           3   \n",
       "625118  NN_180917_113933_C0A0B2_26         26           3   \n",
       "625119  NN_180917_113933_C0A0B2_26         26           3   \n",
       "\n",
       "                                side  \\\n",
       "0        NN_191024_151623_BE78A8_6_L   \n",
       "1        NN_191024_151623_BE78A8_6_L   \n",
       "2        NN_191024_151623_BE78A8_6_L   \n",
       "3        NN_191024_151623_BE78A8_6_L   \n",
       "4        NN_191024_151623_BE78A8_6_R   \n",
       "...                              ...   \n",
       "625115  NN_180917_113933_C0A0B2_26_L   \n",
       "625116  NN_180917_113933_C0A0B2_26_R   \n",
       "625117  NN_180917_113933_C0A0B2_26_R   \n",
       "625118  NN_180917_113933_C0A0B2_26_R   \n",
       "625119  NN_180917_113933_C0A0B2_26_R   \n",
       "\n",
       "                                          multitask_key  angle  \\\n",
       "0           000408 102419 x_NN_191024_151623_BE78A8_6_L    -10   \n",
       "1           000408 102419 x_NN_191024_151623_BE78A8_6_L    -10   \n",
       "2           000408 102419 x_NN_191024_151623_BE78A8_6_L    -10   \n",
       "3           000408 102419 x_NN_191024_151623_BE78A8_6_L    -10   \n",
       "4           000408 102419 x_NN_191024_151623_BE78A8_6_R    -10   \n",
       "...                                                 ...    ...   \n",
       "625115  S594966_2 091718 x_NN_180917_113933_C0A0B2_26_L      9   \n",
       "625116  S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R      9   \n",
       "625117  S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R      9   \n",
       "625118  S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R      9   \n",
       "625119  S594966_2 091718 x_NN_180917_113933_C0A0B2_26_R      9   \n",
       "\n",
       "                                                  pattern  bone_loss  \n",
       "0       Ori_000408 102419 x_NN_191024_151623_BE78A8_6_...          1  \n",
       "1       flip_000408 102419 x_NN_191024_151623_BE78A8_6...          1  \n",
       "2       clahe_000408 102419 x_NN_191024_151623_BE78A8_...          1  \n",
       "3       clahe_flip_000408 102419 x_NN_191024_151623_BE...          1  \n",
       "4       Ori_000408 102419 x_NN_191024_151623_BE78A8_6_...          1  \n",
       "...                                                   ...        ...  \n",
       "625115  clahe_flip_S594966_2 091718 x_NN_180917_113933...          1  \n",
       "625116  Ori_S594966_2 091718 x_NN_180917_113933_C0A0B2...          1  \n",
       "625117  flip_S594966_2 091718 x_NN_180917_113933_C0A0B...          1  \n",
       "625118  clahe_S594966_2 091718 x_NN_180917_113933_C0A0...          1  \n",
       "625119  clahe_flip_S594966_2 091718 x_NN_180917_113933...          1  \n",
       "\n",
       "[591600 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000408 102419 x',\n",
       " '000411 112119 x',\n",
       " '001742 082712 x',\n",
       " '002456 060517 x',\n",
       " '002555 042513 x',\n",
       " '003262 103015 x',\n",
       " '003615 010816 x',\n",
       " '003670 020718 x',\n",
       " '004151 091409 x',\n",
       " '004359 030716 x',\n",
       " '004499 110515 x',\n",
       " '005627 120209 x',\n",
       " '007274 021016 x',\n",
       " '008908 090309 x',\n",
       " '010953 031618 x',\n",
       " '10689 102418 x',\n",
       " '13529 092513 x',\n",
       " '1899 120718 x'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Chang.ID) & set(Sheng_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_three_way_table(Meng_Sheng_Chang_df, all_Chang_df, Chang_Majority_df ):\n",
    "        \n",
    "        base_columns = ['Path', 'State', 'bone_loss', 'Class', 'ID', 'ori_src', 'source', 'tooth_num', 'tooth_type', 'side', 'angle']\n",
    "        \n",
    "        \n",
    "        Meng_Sheng_Chang_columns = [ i + \"_x\" for i in base_columns ]\n",
    "        all_Chang_columns        = [ i + \"_y\" for i in base_columns ]\n",
    "        Chang_Majority_columns   = [ i for i in base_columns        ]\n",
    "        \n",
    "#         print(len(set(Meng_Sheng_Chang_df.ID) & set(Sheng_ID)))\n",
    "#         print(len(set(all_Chang_df.ID) & set(Sheng_ID)))\n",
    "#         print(len(set(Chang_Majority_df.ID) & set(Sheng_ID)))\n",
    "        \n",
    "        intersection_table =  pd.merge(Meng_Sheng_Chang_df, all_Chang_df, on='pattern', how='inner')\n",
    "        intersection_table =  pd.merge(intersection_table, Chang_Majority_df, on='pattern', how='inner')\n",
    "        \n",
    "#         print(len(set(intersection_table.ID) & set(Sheng_ID)))\n",
    "        \n",
    "        new_Meng_Sheng_Chang = intersection_table[Meng_Sheng_Chang_columns].rename( columns={ new: old for new, old in zip(Meng_Sheng_Chang_columns, base_columns)})\n",
    "        new_all_Chang =  intersection_table[all_Chang_columns].rename( columns={ new: old for new, old in zip(all_Chang_columns, base_columns)})\n",
    "        new_majority  =  intersection_table[Chang_Majority_columns].rename(columns= { new: old for new, old in zip(Chang_Majority_columns, base_columns)})\n",
    "        \n",
    "        return new_Meng_Sheng_Chang, new_all_Chang, new_majority\n",
    "        \n",
    "        \n",
    "#         all_table = two_table[new_col].rename(columns={  new: old for new, old in zip(new_col , original_col)} )\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = \"balance_dataset/Common_Dataset/Multi_Class3\"\n",
    "    \n",
    "for fold_num in range(1, 6, 1):\n",
    "        \n",
    "        if not os.path.isdir(f\"{new_dir}_Meng_Sheng_Chang/Fold_{fold_num}\"): \n",
    "                os.makedirs(f\"{new_dir}_Meng_Sheng_Chang/Fold_{fold_num}\") \n",
    "                \n",
    "        if not os.path.isdir(f\"{new_dir}_All_Chang/Fold_{fold_num}\"): \n",
    "                os.makedirs(f\"{new_dir}_All_Chang/Fold_{fold_num}\") \n",
    "                \n",
    "        if not os.path.isdir(f\"{new_dir}_Chang_Majority/Fold_{fold_num}\"): \n",
    "                os.makedirs(f\"{new_dir}_Chang_Majority/Fold_{fold_num}\") \n",
    "                        \n",
    "        for datasets in [\"train_dataset\", \"valid_dataset\", \"test_dataset\"]:\n",
    "                majority = pd.read_csv(f\"{root_dir}/Fold_{fold_num}/{datasets}.csv\")\n",
    "                majority = find_pattern(majority)\n",
    "                majority = map_2_HV_Info(majority)\n",
    "                majority = majority[ (majority.State >= 0) & (majority.bone_loss >= 0) ]\n",
    "                \n",
    "                new_Meng_Sheng_Chang, new_all_Chang, new_majority = merge_three_way_table(Chang_Meng_Sheng, Chang, majority)\n",
    "                \n",
    "                new_Meng_Sheng_Chang.to_csv(f\"{new_dir}_Meng_Sheng_Chang/Fold_{fold_num}/{datasets}.csv\", index=False)        \n",
    "                new_all_Chang.to_csv(f\"{new_dir}_All_Chang/Fold_{fold_num}/{datasets}.csv\", index=False) \n",
    "                new_majority.to_csv(f\"{new_dir}_Chang_Majority/Fold_{fold_num}/{datasets}.csv\", index=False)\n",
    "                \n",
    "                \n",
    "#                 print(len(new_Meng_Sheng_Chang), len(new_all_Chang), len(new_majority))\n",
    "                \n",
    "#         print(merge)\n",
    "#         original_col = Chang.columns[:-1]\n",
    "#         new_col = [ i + \"_x\" for i in original_col ] \n",
    "            \n",
    "#         same_train =  pd.merge(Chang, train_majority, on='pattern', how='inner')\n",
    "#         same_valid =  pd.merge(Chang, valid_majority, on='pattern', how='inner')\n",
    "#         same_test  =  pd.merge(Chang, test_majority , on='pattern', how='inner')\n",
    "\n",
    "#         same_train = same_train[new_col].rename(columns={  new: old for new, old in zip(new_col , original_col)} )\n",
    "#         same_valid = same_valid[new_col].rename(columns={  new: old for new, old in zip(new_col , original_col)} )\n",
    "#         same_test  = same_test[new_col].rename(columns={  new: old for new, old in zip(new_col , original_col)} )\n",
    "\n",
    "#         print(f\"======================== Fold {fold_num} ========================\")\n",
    "#         print(\"Training different\"   ,len(train_majority)-len(same_train))\n",
    "#         print(\"Validation different\" ,len(valid_majority)-len(same_valid))\n",
    "#         print(\"Test different\"       ,len(test_majority) -len(same_test))\n",
    "        \n",
    "#         if not os.path.isdir(f\"{new_Chang_dir}/Fold_{fold_num}\"): os.makedirs(f\"{new_Chang_dir}/Fold_{fold_num}\") \n",
    "            \n",
    "#         same_train.to_csv(f\"{new_Chang_dir}/Fold_{fold_num}/train_dataset.csv\", index=False)\n",
    "#         same_valid.to_csv(f\"{new_Chang_dir}/Fold_{fold_num}/valid_dataset.csv\", index=False)\n",
    "#         same_test.to_csv(f\"{new_Chang_dir}/Fold_{fold_num}/test_dataset.csv\"  , index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
